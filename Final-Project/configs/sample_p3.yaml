inputs:
  ref_prompt: "A `dog, a `cat and a `dog near a forest."
  base_prompt: "A `dog, a `cat and a `dog near a forest."
  negative_prompt: ""
  custom_prompts:
    - "A <welsh_dog_1> `<welsh_dog_2>, a <welsh_dog_1> `<welsh_dog_2> and a <welsh_dog_1> `<welsh_dog_2> near a forest."
    - "A <siberian_cat_1> `<siberian_cat_2>, a <siberian_cat_1> `<siberian_cat_2> and a <siberian_cat_1> `<siberian_cat_2> near a forest."
    - "A <corgi_dog_1> `<corgi_dog_2>, a <corgi_dog_1> `<corgi_dog_2> and a <corgi_dog_1> `<corgi_dog_2> near a forest."

  ref_image_path: "examples/two_dog_one_cat/two_dog_one_cat.png"
  ref_mask_paths:
    - "examples/two_dog_one_cat/mask_dog1.png"
    - "examples/two_dog_one_cat/mask_cat.png"
    - "examples/two_dog_one_cat/mask_dog2.png"  
  init_mask_from_points: False
  mask_center_points: 
    - [400, 250]
    - [250, 100]
    - [100, 250]
  init_image_path: ~
  init_mask_path: ~       
  edlora_paths: 
    - "ed-loras/welsh_dog.pth"
    - "ed-loras/siberian_cat.pth"  
    - "ed-loras/corgi_dog.pth" 
  load_edlora: True
  lora_alpha: 0.4

outputs:
  outroot: "outputs/p3"
  image_outdir: "inference_results"
  latents_outdir: "inverted_latents"
  self_attn_outdir: "self_attn"
  cross_attn_outdir: "cross_attn"
  feature_mask_outdir: "feature_mask"


base_model:
  sd_ckpt: "pretrained_models/chilloutmix"
  variant: ""

sd_t2i:
  height: 512
  width: 512
  guidance_scale: 10
  num_inference_steps: 200
  start_seed: 1230
  batch_size: 2
  n_batches: 2
  verbose: False

attention_operations:
  attn_guidance_end: 60
  attn_guidance_interval: 1
  attn_guidance_weight: 10
  custom_attn_guidance_factor: 1.0

  processor_filter_guidance: '.*up_blocks\.1\.attentions\.0.*attn1.*'
  params_guidance: ["key"]
  processor_filter_mask: '.*up_blocks\.2\.attentions\.2.*attn1.*'
  params_mask: ['attention_probs']
  processor_filter_merge: '.*up_blocks.*'
  params_merge: ["feature_output"]
  processor_filter_view_sa: '.*up_blocks\.2\.attentions\.2.*attn1.*'
  params_view_sa: ["attention_probs"]      
  processor_filter_view_ca: '.*up_blocks\.2\.attentions\.1.*attn2.*'
  params_view_ca: ["attention_probs"]    

  mask_refinement_start: 60
  mask_refinement_end: 70
  mask_update_interval: 1
  mask_overlap_threshold: 0
  num_kmeans_init: 100
  rect_mask: False

  use_loss_mask: False
  visualization: False



